# -*- coding: utf-8 -*-
#
# Copyright (C) GrimoireLab Contributors
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program. If not, see <http://www.gnu.org/licenses/>.
#
# Authors:
#     Santiago Due√±as <sduenas@bitergia.com>
#     Jose Javier Merchante <jjmerchante@bitergia.com>
#

from __future__ import annotations

from typing import TYPE_CHECKING
from typing import Any

import logging
import pickle

import rq
import perceval.backend
import perceval.backends

from .errors import NotFoundError

if TYPE_CHECKING:
    from logging import LogRecord
    from redis import Redis
    from rq.job import Job


logger = logging.getLogger(__name__)


class JobLogHandler(logging.StreamHandler):
    """Handler class for the job logs"""

    def __init__(self, job: Job) -> None:
        logging.StreamHandler.__init__(self)
        self.job = job
        self.job.meta['log'] = []
        self.job.save_meta()

    def emit(self, record: LogRecord) -> None:
        log = {
            'created': record.created,
            'msg': self.format(record),
            'module': record.module,
            'level': self.level
        }
        self.job.meta['log'].append(log)
        self.job.save_meta()


class JobResult:
    """Class to store the result of a Perceval job.

    It stores the summary of a Perceval job and other useful data
    such as the task and job identifiers, the backend and the
    category of the items generated.

    :param job_id: job identifier
    :param task_id: task identifier linked to this job
    :param backend: backend used to fetch the items
    :param category: category of the fetched items
    """

    def __init__(self, job_id: str, task_id: str, backend: str, category: str):
        self.job_id = job_id
        self.task_id = task_id
        self.backend = backend
        self.category = category
        self.summary = None

    def to_dict(self) -> dict[str, str | int]:
        """Convert object to a dict"""

        result = {
            'job_id': self.job_id,
            'task_id': self.task_id
        }

        if self.summary:
            result['fetched'] = self.summary.fetched
            result['skipped'] = self.summary.skipped
            result['min_updated_on'] = self.summary.min_updated_on.timestamp()
            result['max_updated_on'] = self.summary.max_updated_on.timestamp()
            result['last_updated_on'] = self.summary.last_updated_on.timestamp()
            result['last_uuid'] = self.summary.last_uuid
            result['min_offset'] = self.summary.min_offset
            result['max_offset'] = self.summary.max_offset
            result['last_offset'] = self.summary.last_offset
            result['extras'] = self.summary.extras

        return result


class PercevalJob:
    """Class for wrapping Perceval jobs.

    Wrapper for running and executing Perceval backends. The items
    generated by the execution of a backend will be stored on the
    Redis queue named `qitems`. The result of the job can be obtained
    accessing to the property `result` of this object.

    :param job_id: job identifier
    :param task_id: task identifier linked to this job
    :param backend: name of the backend to execute
    :param conn: connection with a Redis database
    :param qitems: name of the queue where items will be stored

    :raises NotFoundError: raised when the backend is not available
        in Perceval
    """

    def __init__(
            self,
            job_id: str,
            task_id: str,
            backend: str,
            category: str,
            conn: Redis,
            qitems: str
    ) -> None:
        try:
            self._bklass = perceval.backend.find_backends(perceval.backends)[0][backend]
        except KeyError:
            raise NotFoundError(element=backend)

        self.job_id = job_id
        self.task_id = task_id
        self.backend = backend
        self.conn = conn
        self.qitems = qitems
        self.category = category

        self._big = None  # items generator
        self._result = JobResult(self.job_id, self.task_id,
                                 self.backend, self.category)

    @property
    def result(self) -> JobResult:
        if not self._result.summary and self._big and self._big.summary:
            self._result.summary = self._big.summary
        return self._result

    def run(self, backend_args: dict[str, Any]) -> None:
        """Run the backend with the given parameters.

        The method will run the backend assigned to this job,
        storing the fetched items in a Redis queue. The ongoing
        status of the job, can be accessed through the property
        `result`.

        Any exception during the execution of the process will
        be raised.

        :param backend_args: parameters used to un the backend
        """
        backend_args = backend_args.copy()

        self._result = JobResult(self.job_id, self.task_id,
                                 self.backend, self.category)

        self._big = perceval.backend.BackendItemsGenerator(self._bklass,
                                                           backend_args,
                                                           self.category)

        for item in self._big.items:
            self._metadata(item)
            self.conn.rpush(self.qitems, pickle.dumps(item))

    def has_resuming(self) -> bool:
        """Returns if the job can be resumed when it fails"""

        return self._bklass.has_resuming()

    def _metadata(self, item: dict[str, Any]) -> None:
        """Add metadata to an item.

        Method that adds in place metadata to Perceval items such as
        the identifier of the job that generated it or the version of
        the system.

        :param item: an item generated by Perceval
        """
        # TODO: add Arthur version?
        item['job_id'] = self.job_id


def execute_perceval_job(
        backend: str,
        backend_args: dict,
        qitems: str,
        task_id: str,
        category: str
) -> JobResult:
    """Execute a Perceval job on RQ.

    The items fetched during the process will be stored in a
    Redis queue named `queue`.

    :param backend: backend to execute
    :param backend_args: dict of arguments for running the backend
    :param qitems: name of the RQ queue used to store the items
    :param task_id: identifier of the task linked to this job
    :param category: category of the items to retrieve

    :returns: a `JobResult` instance

    :raises NotFoundError: raised when the backend is not found
    """
    rq_job = rq.get_current_job()

    job = PercevalJob(rq_job.id, task_id, backend, category,
                      rq_job.connection, qitems)

    job_logger = JobLogHandler(rq_job)
    for logger_name in [__name__, 'perceval', 'rq']:
        logger_job = logging.getLogger(logger_name)
        logger_job.setLevel(logging.INFO)
        logger_job.addHandler(job_logger)

    logger.debug("Running job #%s (task: %s) (%s) (cat:%s)",
                 job.job_id, task_id, backend, category)

    try:
        job.run(backend_args)
        result = job.result

        logger.debug("Job #%s (task: %s) completed (%s) - %s/%s items (%s) fetched",
                     result.job_id, task_id, result.backend,
                     str(result.summary.fetched), str(result.summary.skipped),
                     result.category)
    except AttributeError as e:
        raise e
    except Exception as e:
        rq_job = rq.get_current_job()
        rq_job.meta['result'] = job.result
        rq_job.save_meta()
        logger.debug("Error running job %s (%s) - %s",
                     job.job_id, backend, str(e))
        raise e
    finally:
        for logger_name in [__name__, 'perceval', 'rq']:
            logger_job = logging.getLogger(logger_name)
            logger_job.removeHandler(job_logger)

    return job.result
